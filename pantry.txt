Это кладовка для кода, который пока не нашел применения или его применение сомнительно

void TVideo_reader::pgm_save_gray(int wrap, const char *filename) noexcept
{
    if (m_isError)
        return;
        FILE *f = nullptr;
        f = fopen(filename,"wb");
    //fprintf(f, "P5\n%d %d\n%d\n", m_frame_width, m_frame_height, 255);
    fmsgr << "P5" << nl << m_frame_width << " " << m_frame_height << nl << 255 << mend;
    const char* str = fmsgr.getString();
    std::size_t lng = strlen(str) ;
    fwrite(str, lng, 1, f );
    for (int i = 0; i < m_frame_height; i++)
        fwrite(m_videodata + i * m_frame_width, m_frame_width, 1, f);
        fclose(f);
}


static AVFrame *crop_frame(const AVFrame *in, int left, int top, int right, int bottom)
{
    AVFilterContext *buffersink_ctx;
    AVFilterContext *buffersrc_ctx;
    AVFilterGraph *filter_graph = avfilter_graph_alloc();
    AVFrame *f = av_frame_alloc();
    AVFilterInOut *inputs = NULL, *outputs = NULL;
    char args[512];
    int ret;
    /*
    snprintf(args, sizeof(args),
             "buffer=video_size=%dx%d:pix_fmt=%d:time_base=1/1:pixel_aspect=0/1[in];"
             "[in]crop=x=%d:y=%d:out_w=in_w-x-%d:out_h=in_h-y-%d[out];"
             "[out]buffersink",
             frame->width, frame->height, frame->format,
             left, top, right, bottom);
    */
    snprintf(args, sizeof(args),
             "buffer=video_size=%dx%d:pix_fmt=%d:time_base=1/1:pixel_aspect=0/1[in];"
             "[in]crop=x=%d:y=%d:out_w=in_w-x-%d:out_h=in_h-y-%d[out];"
             "[out]buffersink",
             in->width, in->height, in->format,
             left, top, right, bottom);
    ret = avfilter_graph_parse2(filter_graph, args, &inputs, &outputs);
    if (ret < 0) return NULL;
    assert(inputs == NULL && outputs == NULL);
    ret = avfilter_graph_config(filter_graph, NULL);
    if (ret < 0) return NULL;

    buffersrc_ctx = avfilter_graph_get_filter(filter_graph, "Parsed_buffer_0");
    buffersink_ctx = avfilter_graph_get_filter(filter_graph, "Parsed_buffersink_2");
    assert(buffersrc_ctx != NULL);
    assert(buffersink_ctx != NULL);

    av_frame_ref(f, in);
    ret = av_buffersrc_add_frame(buffersrc_ctx, f);
    if (ret < 0) return NULL;
    ret = av_buffersink_get_frame(buffersink_ctx, f);
    if (ret < 0) return NULL;

    avfilter_graph_free(&filter_graph);

    return f;
}

bool TVideo_reader::save_frame_as_jpeg(int FrameNo) noexcept
{
        const AVCodec *jpegCodec = avcodec_find_encoder(AV_CODEC_ID_JPEG2000);
    if (!jpegCodec)
    {
        return false;
        }
        AVCodecContext *jpegContext = avcodec_alloc_context3(jpegCodec);
    if (!jpegContext)
    {
        return false;
        }

    jpegContext->pix_fmt = m_av_codec_ctx_video->pix_fmt;
    jpegContext->height = m_av_frame_video->height;
    jpegContext->width = m_av_frame_video->width;
        jpegContext->time_base.num = 0;
        jpegContext->time_base.den = 0;
    if (avcodec_open2(jpegContext, jpegCodec, NULL) < 0)
    {
        return false;
        }
        FILE *JPEGFile;
        char JPEGFName[256];

        //AVPacket packet = {.data = NULL, .size = 0};
        AVPacket* packet = av_packet_alloc();
    av_init_packet(packet);
        /*
    int gotFrame;
        if (avcodec_encode_video2(jpegContext, &packet, pFrame, &gotFrame) < 0)
        {
                return -1;
        }
        */
        AVFrame* av_rawframe = av_frame_alloc();
        if (!av_rawframe)
        {
        showerrmsg("Couldn't allocate AVFrame");
                return false;
        }
    av_rawframe->width = m_av_frame_video->width;
    av_rawframe->height = m_av_frame_video->height;
        av_rawframe->format = AV_PIX_FMT_RGB24;
        int response =  av_image_fill_arrays(av_rawframe->data,
                                         m_av_frame_video->linesize,
                                         m_av_frame_video->data[0],
                                                                                 AV_PIX_FMT_RGB24,
                                         m_av_frame_video->width,
                                         m_av_frame_video->height,
                                                                                 1);
        if (response < 0)
        {
        showerrmsg("Failed to fill frame");
                return false;
        }
        //if (response == AVERROR(EAGAIN) || response == AVERROR_EOF)
        //{
        //	continue;
        //}
        //else if (response < 0)
        //{
        //	printf("Failed to decode packet\n");
        //	return false;
        //}
        //avpicture_fill((AVPicture*)av_rawframe, NULL, av_rawframe->format, av_rawframe->width, av_rawframe->height);
        //av_write_frame()
        response = avcodec_send_frame(jpegContext, av_rawframe);
        if (response < 0)
        {
        showerrmsg("Failed to decode packet");
                return false;
        }
        response = avcodec_receive_packet(jpegContext, packet);
        if (response < 0)
        {
        showerrmsg("Failed to receive packet");
                return false;
        }
        sprintf(JPEGFName, "dvr-%06d.jpg", FrameNo);
        JPEGFile = fopen(JPEGFName, "wb");
        fwrite(packet->data, 1, packet->size, JPEGFile);
        fclose(JPEGFile);

        av_packet_free(&packet);
        avcodec_close(jpegContext);
    return true;
}


static int get_format_from_sample_fmt(const char **fmt,
                                                                          enum AVSampleFormat sample_fmt)
{
        int i;
        struct sample_fmt_entry {
                enum AVSampleFormat sample_fmt; const char *fmt_be, *fmt_le;
        } sample_fmt_entries[] = {
                { AV_SAMPLE_FMT_U8,  "u8",    "u8"    },
                { AV_SAMPLE_FMT_S16, "s16be", "s16le" },
                { AV_SAMPLE_FMT_S32, "s32be", "s32le" },
                { AV_SAMPLE_FMT_FLT, "f32be", "f32le" },
                { AV_SAMPLE_FMT_DBL, "f64be", "f64le" },
        };
        *fmt = NULL;

        for (i = 0; i < FF_ARRAY_ELEMS(sample_fmt_entries); i++) {
                struct sample_fmt_entry *entry = &sample_fmt_entries[i];
                if (sample_fmt == entry->sample_fmt) {
                        *fmt = AV_NE(entry->fmt_be, entry->fmt_le);
                        return 0;
                }
        }

        fprintf(stderr,
                        "sample format %s is not supported as output format\n",
                        av_get_sample_fmt_name(sample_fmt));
        return -1;
}

template<class T>
class shared_ptr
{
    struct aux
    {
        unsigned count;

        aux() :count(1) {}
        virtual void destroy()=0;
        virtual ~aux() {} //must be polymorphic
    };

    template<class U, class Deleter>
    struct auximpl: public aux
    {
        U* p;
        Deleter d;

        auximpl(U* pu, Deleter x) :p(pu), d(x) {}
        virtual void destroy() { d(p); }
    };

    template<class U>
    struct default_deleter
    {
        void operator()(U* p) const { delete p; }
    };

    aux* pa;
    T* pt;

    void inc() { if(pa) interlocked_inc(pa->count); }

    void dec()
    {
        if(pa && !interlocked_dec(pa->count))
        {  pa->destroy(); delete pa; }
    }

public:

    shared_ptr() :pa(), pt() {}

    template<class U, class Deleter>
    shared_ptr(U* pu, Deleter d) :pa(new auximpl<U,Deleter>(pu,d)), pt(pu) {}

    template<class U>
    explicit shared_ptr(U* pu) :pa(new auximpl<U,default_deleter<U> >(pu,default_deleter<U>())), pt(pu) {}

    shared_ptr(const shared_ptr& s) :pa(s.pa), pt(s.pt) { inc(); }

    template<class U>
    shared_ptr(const shared_ptr<U>& s) :pa(s.pa), pt(s.pt) { inc(); }

    ~shared_ptr() { dec(); }

    shared_ptr& operator=(const shared_ptr& s)
    {
        if(this!=&s)
        {
            dec();
            pa = s.pa; pt=s.pt;
            inc();
        }
        return *this;
    }

    T* operator->() const { return pt; }
    T& operator*() const { return *pt; }
};
